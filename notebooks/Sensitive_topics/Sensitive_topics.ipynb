{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sensitive_topics",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install git-lfs\n",
        "!git lfs install"
      ],
      "metadata": {
        "id": "9JxfXPXsjFlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://huggingface.co/Skoltech/russian-sensitive-topics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h87ERkQxiWSL",
        "outputId": "78edea94-c6ad-4c8c-83ad-21b664ab7d88"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'russian-sensitive-topics'...\n",
            "remote: Enumerating objects: 36, done.\u001b[K\n",
            "remote: Counting objects: 100% (36/36), done.\u001b[K\n",
            "remote: Compressing objects: 100% (35/35), done.\u001b[K\n",
            "remote: Total 36 (delta 14), reused 0 (delta 0)\u001b[K\n",
            "Unpacking objects: 100% (36/36), done.\n",
            "Filtering content: 100% (4/4), 1.99 GiB | 55.57 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from graph import InferenceWorker\n",
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import BertTokenizerFast\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained('/content/russian-sensitive-topics')\n",
        "model = AutoModelForSequenceClassification.from_pretrained('/content/russian-sensitive-topics', return_dict=True)"
      ],
      "metadata": {
        "id": "GQ9j4ty-n9WB"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'В стране карантин. Умерло очень много людей.'"
      ],
      "metadata": {
        "id": "ma0fXDOop6hQ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text1 = 'ЦИК Туркменистана сообщил, что досрочные выборы президента назначены на 12 марта. Накануне вечером действующий глава государства Гурбангулы Бердымухамедов заявил, что принял \"непростое решение о себе\" и что путь во властные структуры следует предоставить молодым руководителям.'"
      ],
      "metadata": {
        "id": "tpor_Go1uli_"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SampleSensitive(InferenceWorker):\n",
        "    def __call__(self, t, d):\n",
        "        if t == \"text\":\n",
        "            yield \"sensitive\", self.predict(d), \"Sensitive_topics\"\n",
        "        else:\n",
        "            yield None        \n",
        "    @torch.no_grad()\n",
        "    def predict(self, text):\n",
        "        inputs = tokenizer(text, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
        "        outputs = model(**inputs)\n",
        "        predicted = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
        "        predicted = torch.argmax(predicted, dim=1).numpy()\n",
        "        if predicted[0] == 1:\n",
        "          return 'offline_crime'\n",
        "        if predicted[0] == 2:\n",
        "          return 'online_crime'\n",
        "        if predicted[0] == 3:\n",
        "          return 'drugs'   \n",
        "        if predicted[0] == 4:\n",
        "          return 'gambling'\n",
        "        if predicted[0] == 5:\n",
        "          return 'pornography'\n",
        "        if predicted[0] == 6:\n",
        "          return 'prostitution'  \n",
        "        if predicted[0] == 7:\n",
        "          return 'slavery'\n",
        "        if predicted[0] == 8:\n",
        "          return 'suicide'\n",
        "        if predicted[0] == 9:\n",
        "          return 'terrorism'  \n",
        "        if predicted[0] == 10:\n",
        "          return 'weapons'\n",
        "        if predicted[0] == 11:\n",
        "          return 'body_shaming'\n",
        "        if predicted[0] == 12:\n",
        "          return 'health_shaming'\n",
        "        if predicted[0] == 13:\n",
        "          return 'politics' \n",
        "        if predicted[0] == 14:\n",
        "          return 'racism'\n",
        "        if predicted[0] == 15:\n",
        "          return 'religion'   \n",
        "        if predicted[0] == 16:\n",
        "          return 'sexual_minorities'\n",
        "        if predicted[0] == 17:\n",
        "          return 'sexism'\n",
        "        if predicted[0] == 18:\n",
        "          return 'social_injustice' \n"
      ],
      "metadata": {
        "id": "2xbz64gGosZ9"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "worker = SampleSensitive()\n",
        "worker.serialize()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqF-XuncpxgP",
        "outputId": "fe3d0f1b-0180-47f6-d84a-f1bc9c0ec8f0"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Worker saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x in worker(\"text\", text):\n",
        "  print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5jFlsHTp1DS",
        "outputId": "35253d71-eb4f-469c-ef62-4529560ade80"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('sensitive', 'offline_crime', 'Sensitive_topics')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x in worker(\"text\", text1):\n",
        "  print(x)"
      ],
      "metadata": {
        "id": "ckss7Hg9rT6O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46ab0a7c-efb4-4c56-bd9b-50312a1e5bba"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('sensitive', 'racism', 'Sensitive_topics')\n"
          ]
        }
      ]
    }
  ]
}